"""
YOLO11 Tracking Script
Ch∆∞∆°ng tr√¨nh tracking ng∆∞·ªùi c√≥/kh√¥ng c√≥ m≈© b·∫£o hi·ªÉm t·ª´ video ho·∫∑c ·∫£nh
"""

import os
import sys
from pathlib import Path
from ultralytics import YOLO
import torch
import cv2
import argparse
import yaml

# ƒê∆∞·ªùng d·∫´n model m·∫∑c ƒë·ªãnh
DEFAULT_MODEL_PATH = 'runs/detect/helmet-detection/weights/best.pt'
# ƒê∆∞·ªùng d·∫´n args.yaml m·∫∑c ƒë·ªãnh (n·∫øu c√≥)
DEFAULT_ARGS_PATH = 'runs/detect/helmet-detection/args.yaml'


def load_args_config(args_path=None):
    """
    Load c·∫•u h√¨nh t·ª´ args.yaml n·∫øu c√≥
    
    Args:
        args_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn args.yaml (None ƒë·ªÉ t·ª± ƒë·ªông t√¨m)
    
    Returns:
        dict: Dictionary ch·ª©a c√°c tham s·ªë t·ª´ args.yaml ho·∫∑c None
    """
    if args_path is None:
        args_path = DEFAULT_ARGS_PATH
    
    if not os.path.exists(args_path):
        return None
    
    try:
        with open(args_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print(f"‚úÖ ƒê√£ load c·∫•u h√¨nh t·ª´: {args_path}")
        return config
    except Exception as e:
        print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ load args.yaml: {e}")
        return None


def track_video(model_path, video_path, output_dir='runs/track', conf=0.25, tracker='bytetrack.yaml', show=False, args_config=None):
    """
    Track objects trong video
    
    Args:
        model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn model ƒë√£ train (.pt)
        video_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn video file ho·∫∑c webcam (0, 1, 2...)
        output_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
        conf: Confidence threshold
        tracker: Lo·∫°i tracker (bytetrack.yaml, botsort.yaml)
        show: Hi·ªÉn th·ªã video real-time
    """
    print(f"\n{'='*60}")
    print("TRACKING VIDEO")
    print(f"{'='*60}")
    
    # Load model
    print(f"ƒêang load model t·ª´: {model_path}")
    try:
        model = YOLO(model_path)
        print("‚úÖ Model ƒë√£ ƒë∆∞·ª£c load th√†nh c√¥ng!")
    except Exception as e:
        print(f"‚ùå L·ªói khi load model: {e}")
        return None
    
    # Ki·ªÉm tra video path
    is_webcam = False
    if isinstance(video_path, str) and video_path.isdigit():
        video_path = int(video_path)
        is_webcam = True
        print(f"üìπ ƒêang s·ª≠ d·ª•ng webcam: {video_path}")
    else:
        if not os.path.exists(video_path):
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y video: {video_path}")
            return None
        print(f"üìπ ƒêang x·ª≠ l√Ω video: {video_path}")
    
    # √Åp d·ª•ng c·∫•u h√¨nh t·ª´ args.yaml n·∫øu c√≥
    imgsz = 640
    iou = 0.7
    device = 0 if torch.cuda.is_available() else 'cpu'
    
    if args_config:
        # L·∫•y c√°c tham s·ªë t·ª´ args.yaml
        if args_config.get('imgsz'):
            imgsz = args_config['imgsz']
        if args_config.get('iou'):
            iou = args_config['iou']
        if args_config.get('device'):
            device = args_config['device']
        if args_config.get('conf') is not None and conf == 0.25:  # Ch·ªâ d√πng n·∫øu ch∆∞a ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
            conf = args_config['conf'] if args_config['conf'] else 0.25
        # L·∫•y tracker t·ª´ args.yaml n·∫øu c√≥ (nh∆∞ng v·∫´n ∆∞u ti√™n tham s·ªë truy·ªÅn v√†o)
        if args_config.get('tracker') and tracker == 'bytetrack.yaml':
            tracker_from_args = args_config['tracker']
            if tracker_from_args in ['bytetrack.yaml', 'botsort.yaml']:
                tracker = tracker_from_args
    
    # Th√¥ng tin x·ª≠ l√Ω
    print(f"\n‚öôÔ∏è  C·∫•u h√¨nh:")
    print(f"   - Confidence threshold: {conf}")
    print(f"   - Tracker: {tracker}")
    print(f"   - Image size: {imgsz}")
    print(f"   - IOU threshold: {iou}")
    print(f"   - Device: {device}")
    print(f"   - Hi·ªÉn th·ªã real-time: {'C√≥' if show else 'Kh√¥ng'}")
    if args_config:
        print(f"   - üìã ƒê√£ √°p d·ª•ng c·∫•u h√¨nh t·ª´ args.yaml")
    print(f"\nüîÑ ƒêang x·ª≠ l√Ω video...")
    
    # Track video
    try:
        results = model.track(
            source=video_path,
            conf=conf,
            tracker=tracker,
            save=True,
            project=output_dir,
            name='helmet-tracking',
            exist_ok=True,
            show=show,
            save_txt=True,  # L∆∞u tracking results d·∫°ng text
            save_conf=True,
            line_width=2,
            verbose=True,
            imgsz=imgsz,  # K√≠ch th∆∞·ªõc ·∫£nh x·ª≠ l√Ω t·ª´ args.yaml
            iou=iou,  # IOU threshold t·ª´ args.yaml
            device=device  # Device t·ª´ args.yaml
        )
        
        # Th·ªëng k√™ k·∫øt qu·∫£
        print(f"\n{'='*60}")
        print("TH·ªêNG K√ä K·∫æT QU·∫¢")
        print(f"{'='*60}")
        
        total_frames = 0
        total_helmet = 0
        total_no_helmet = 0
        unique_tracks = set()
        
        for result in results:
            total_frames += 1
            if result.boxes is not None and len(result.boxes) > 0:
                for box in result.boxes:
                    cls = int(box.cls[0])
                    class_name = model.names[cls]
                    
                    # L·∫•y tracking ID n·∫øu c√≥
                    if hasattr(box, 'id') and box.id is not None:
                        track_id = int(box.id[0])
                        unique_tracks.add(track_id)
                    
                    if 'with_helmet' in class_name:
                        total_helmet += 1
                    elif 'without_helmet' in class_name:
                        total_no_helmet += 1
        
        print(f"üìä T·ªïng s·ªë frame ƒë√£ x·ª≠ l√Ω: {total_frames}")
        print(f"üë§ T·ªïng s·ªë object ƒë∆∞·ª£c ph√°t hi·ªán:")
        print(f"   - C√≥ m≈© b·∫£o hi·ªÉm: {total_helmet}")
        print(f"   - Kh√¥ng c√≥ m≈© b·∫£o hi·ªÉm: {total_no_helmet}")
        print(f"   - T·ªïng c·ªông: {total_helmet + total_no_helmet}")
        if unique_tracks:
            print(f"üÜî S·ªë l∆∞·ª£ng object unique ƒë∆∞·ª£c track: {len(unique_tracks)}")
        
        print(f"\n‚úÖ Ho√†n th√†nh! K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_dir}/helmet-tracking")
        if not is_webcam:
            output_video = os.path.join(output_dir, 'helmet-tracking', os.path.basename(video_path))
            if os.path.exists(output_video):
                print(f"üìπ Video ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_video}")
        
        return results
        
    except Exception as e:
        print(f"‚ùå L·ªói khi x·ª≠ l√Ω video: {e}")
        import traceback
        traceback.print_exc()
        return None


def detect_image(model_path, image_path, output_dir='runs/detect', conf=0.25, show=False):
    """
    Detect objects trong ·∫£nh (kh√¥ng c√≥ tracking v√¨ ch·ªâ l√† ·∫£nh ƒë∆°n)
    
    Args:
        model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn model ƒë√£ train (.pt)
        image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh ho·∫∑c th∆∞ m·ª•c ·∫£nh
        output_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
        conf: Confidence threshold
        show: Hi·ªÉn th·ªã ·∫£nh
    """
    print(f"\n{'='*60}")
    print("DETECT ·∫¢NH")
    print(f"{'='*60}")
    
    # Load model
    print(f"ƒêang load model t·ª´: {model_path}")
    model = YOLO(model_path)
    
    # Ki·ªÉm tra image path
    if not os.path.exists(image_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh/th∆∞ m·ª•c: {image_path}")
        return
    
    # Detect ·∫£nh
    results = model.predict(
        source=image_path,
        conf=conf,
        save=True,
        project=output_dir,
        name='helmet-detect',
        exist_ok=True,
        show=show,
        save_txt=True,
        save_conf=True,
        line_width=2,
        verbose=True
    )
    
    # Hi·ªÉn th·ªã th·ªëng k√™
    print(f"\n{'='*60}")
    print("TH·ªêNG K√ä K·∫æT QU·∫¢")
    print(f"{'='*60}")
    
    total_helmet = 0
    total_no_helmet = 0
    
    for result in results:
        for box in result.boxes:
            cls = int(box.cls[0])
            class_name = model.names[cls]
            if 'with_helmet' in class_name:
                total_helmet += 1
            elif 'without_helmet' in class_name:
                total_no_helmet += 1
    
    print(f"T·ªïng s·ªë ng∆∞·ªùi c√≥ m≈© b·∫£o hi·ªÉm: {total_helmet}")
    print(f"T·ªïng s·ªë ng∆∞·ªùi kh√¥ng c√≥ m≈© b·∫£o hi·ªÉm: {total_no_helmet}")
    print(f"T·ªïng s·ªë ng∆∞·ªùi: {total_helmet + total_no_helmet}")
    
    print(f"\n‚úÖ Ho√†n th√†nh! K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_dir}/helmet-detect")
    return results


def main():
    parser = argparse.ArgumentParser(
        description='Tracking v√† Detection m≈© b·∫£o hi·ªÉm v·ªõi YOLO11',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
V√≠ d·ª• s·ª≠ d·ª•ng:
  # Track video
  python track.py --mode video --source video.mp4
  
  # Track webcam
  python track.py --mode video --source 0
  
  # Detect ·∫£nh
  python track.py --mode image --source image.jpg
  
  # Detect th∆∞ m·ª•c ·∫£nh
  python track.py --mode image --source folder/
        """
    )
    
    parser.add_argument('--mode', type=str, choices=['video', 'image'], required=True,
                       help='Ch·∫ø ƒë·ªô: video (tracking) ho·∫∑c image (detection)')
    parser.add_argument('--source', type=str, required=True,
                       help='ƒê∆∞·ªùng d·∫´n video/·∫£nh ho·∫∑c webcam (0, 1, 2...)')
    parser.add_argument('--model', type=str, default=DEFAULT_MODEL_PATH,
                       help=f'ƒê∆∞·ªùng d·∫´n ƒë·∫øn model ƒë√£ train (m·∫∑c ƒë·ªãnh: {DEFAULT_MODEL_PATH})')
    parser.add_argument('--conf', type=float, default=0.25,
                       help='Confidence threshold (m·∫∑c ƒë·ªãnh: 0.25)')
    parser.add_argument('--tracker', type=str, default='bytetrack.yaml',
                       choices=['bytetrack.yaml', 'botsort.yaml'],
                       help='Lo·∫°i tracker (m·∫∑c ƒë·ªãnh: bytetrack.yaml)')
    parser.add_argument('--show', action='store_true',
                       help='Hi·ªÉn th·ªã k·∫øt qu·∫£ real-time')
    parser.add_argument('--output', type=str, default=None,
                       help='Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£ (m·∫∑c ƒë·ªãnh: runs/track cho video, runs/detect cho ·∫£nh)')
    parser.add_argument('--args', type=str, default=None,
                       help='ƒê∆∞·ªùng d·∫´n ƒë·∫øn args.yaml ƒë·ªÉ load c·∫•u h√¨nh (m·∫∑c ƒë·ªãnh: t·ª± ƒë·ªông t√¨m)')
    parser.add_argument('--no-args', action='store_true',
                       help='Kh√¥ng s·ª≠ d·ª•ng c·∫•u h√¨nh t·ª´ args.yaml')
    
    args = parser.parse_args()
    
    # Load args.yaml n·∫øu c√≥
    args_config = None
    if not args.no_args:
        args_config = load_args_config(args.args)
    
    # Ki·ªÉm tra model
    if not os.path.exists(args.model):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y model t·∫°i: {args.model}")
        print(f"Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n ho·∫∑c train model tr∆∞·ªõc!")
        sys.exit(1)
    
    # Ki·ªÉm tra CUDA
    print(f"PyTorch version: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA device: {torch.cuda.get_device_name(0)}")
    
    # X·ª≠ l√Ω theo mode
    if args.mode == 'video':
        output_dir = args.output if args.output else 'runs/track'
        track_video(
            model_path=args.model,
            video_path=args.source,
            output_dir=output_dir,
            conf=args.conf,
            tracker=args.tracker,
            show=args.show,
            args_config=args_config
        )
    elif args.mode == 'image':
        output_dir = args.output if args.output else 'runs/detect'
        detect_image(
            model_path=args.model,
            image_path=args.source,
            output_dir=output_dir,
            conf=args.conf,
            show=args.show
        )


def interactive_mode():
    """Ch·∫ø ƒë·ªô t∆∞∆°ng t√°c v·ªõi menu"""
    print(f"\n{'='*60}")
    print("CH∆Ø∆†NG TR√åNH TRACKING M≈® B·∫¢O HI·ªÇM")
    print(f"{'='*60}\n")
    
    # S·ª≠ d·ª•ng model m·∫∑c ƒë·ªãnh
    model_path = DEFAULT_MODEL_PATH
    print(f"üì¶ S·ª≠ d·ª•ng model: {model_path}")
    
    if not os.path.exists(model_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y model t·∫°i: {model_path}")
        print(f"Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n ho·∫∑c train model tr∆∞·ªõc!")
        return
    
    # T·ª± ƒë·ªông load args.yaml n·∫øu c√≥
    args_config = load_args_config()
    if args_config:
        print(f"üìã ƒê√£ t√¨m th·∫•y args.yaml, s·∫Ω s·ª≠ d·ª•ng c·∫•u h√¨nh t·ª´ file n√†y")
        use_args = input("   S·ª≠ d·ª•ng c·∫•u h√¨nh t·ª´ args.yaml? (y/n) [y]: ").strip().lower()
        if use_args and use_args != 'y':
            args_config = None
    else:
        args_config = None
    
    # Mode selection
    print("\nCh·ªçn ch·∫ø ƒë·ªô:")
    print("1. Track video")
    print("2. Detect ·∫£nh")
    choice = input("L·ª±a ch·ªçn (1/2): ").strip()
    
    if choice == '1':
        print("\nüìπ Ch·ªçn ngu·ªìn video:")
        print("1. Video file")
        print("2. Webcam")
        source_choice = input("L·ª±a ch·ªçn (1/2) [1]: ").strip()
        
        if source_choice == '2':
            cam_id = input("Nh·∫≠p ID webcam (0, 1, 2...) [0]: ").strip()
            source = cam_id if cam_id else '0'
        else:
            source = input("ƒê∆∞·ªùng d·∫´n video file: ").strip()
            if not source:
                print("‚ùå Vui l√≤ng nh·∫≠p ƒë∆∞·ªùng d·∫´n video!")
                return
            # Lo·∫°i b·ªè d·∫•u ngo·∫∑c k√©p n·∫øu c√≥
            source = source.strip('"').strip("'")
        
        # Confidence threshold - Ng∆∞·ª°ng tin c·∫≠y (0.0 - 1.0)
        # Gi√° tr·ªã c√†ng th·∫•p, model c√†ng ph√°t hi·ªán nhi·ªÅu object (nh∆∞ng c√≥ th·ªÉ c√≥ false positive)
        # Gi√° tr·ªã c√†ng cao, model c√†ng ch√≠nh x√°c (nh∆∞ng c√≥ th·ªÉ b·ªè s√≥t object)
        print("\n‚öôÔ∏è  Confidence threshold (0.0 - 1.0):")
        print("   - Gi√° tr·ªã th·∫•p (0.1-0.3): Ph√°t hi·ªán nhi·ªÅu h∆°n, c√≥ th·ªÉ c√≥ l·ªói")
        print("   - Gi√° tr·ªã cao (0.5-0.9): Ch√≠nh x√°c h∆°n, c√≥ th·ªÉ b·ªè s√≥t")
        conf_input = input("   Nh·∫≠p gi√° tr·ªã [0.25]: ").strip()
        try:
            conf = float(conf_input) if conf_input else 0.25
            if conf < 0 or conf > 1:
                print("‚ö†Ô∏è  Gi√° tr·ªã kh√¥ng h·ª£p l·ªá, s·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh 0.25")
                conf = 0.25
        except ValueError:
            print("‚ö†Ô∏è  Gi√° tr·ªã kh√¥ng h·ª£p l·ªá, s·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh 0.25")
            conf = 0.25
        
        # Tracker - Thu·∫≠t to√°n tracking
        # bytetrack.yaml: Nhanh, hi·ªáu qu·∫£ cho ƒëa s·ªë tr∆∞·ªùng h·ª£p
        # botsort.yaml: Ch√≠nh x√°c h∆°n, t·ªët cho object di chuy·ªÉn nhanh
        print("\n‚öôÔ∏è  Tracker (thu·∫≠t to√°n theo d√µi object):")
        print("   1. bytetrack.yaml - Nhanh, hi·ªáu qu·∫£ (khuy·∫øn ngh·ªã)")
        print("   2. botsort.yaml - Ch√≠nh x√°c h∆°n, t·ªët cho object di chuy·ªÉn nhanh")
        tracker_choice = input("   L·ª±a ch·ªçn (1/2) [1]: ").strip()
        if tracker_choice == '2':
            tracker = 'botsort.yaml'
        else:
            tracker = 'bytetrack.yaml'
        
        show_input = input("Hi·ªÉn th·ªã video real-time? (y/n) [y]: ").strip().lower()
        show = show_input == 'y' if show_input else True  # M·∫∑c ƒë·ªãnh l√† True
        
        track_video(model_path, source, conf=conf, tracker=tracker, show=show, args_config=args_config)
    
    elif choice == '2':
        source = input("ƒê∆∞·ªùng d·∫´n ·∫£nh ho·∫∑c th∆∞ m·ª•c ·∫£nh: ").strip()
        if not source:
            print("‚ùå Vui l√≤ng nh·∫≠p ƒë∆∞·ªùng d·∫´n ·∫£nh ho·∫∑c th∆∞ m·ª•c!")
            return
        
        conf = input("Confidence threshold [0.25]: ").strip()
        conf = float(conf) if conf else 0.25
        
        show = input("Hi·ªÉn th·ªã ·∫£nh? (y/n) [n]: ").strip().lower() == 'y'
        
        detect_image(model_path, source, conf=conf, show=show)
    
    else:
        print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")


if __name__ == '__main__':
    # N·∫øu kh√¥ng c√≥ tham s·ªë d√≤ng l·ªánh, ch·∫°y ch·∫ø ƒë·ªô t∆∞∆°ng t√°c
    if len(sys.argv) == 1:
        interactive_mode()
    else:
        main()

