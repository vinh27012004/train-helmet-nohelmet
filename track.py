"""
YOLO11 Tracking Script
Ch∆∞∆°ng tr√¨nh tracking ng∆∞·ªùi c√≥/kh√¥ng c√≥ m≈© b·∫£o hi·ªÉm t·ª´ video ho·∫∑c ·∫£nh
"""

import os
import sys
from pathlib import Path
from ultralytics import YOLO
import torch
import cv2
import argparse
import yaml

# ƒê∆∞·ªùng d·∫´n model m·∫∑c ƒë·ªãnh
DEFAULT_MODEL_PATH = 'runs/detect/helmet-detection/weights/best.pt'
# ƒê∆∞·ªùng d·∫´n args.yaml m·∫∑c ƒë·ªãnh (n·∫øu c√≥)
DEFAULT_ARGS_PATH = 'runs/detect/helmet-detection/args.yaml'


def detect_source_type(source):
    """
    T·ª± ƒë·ªông ph√°t hi·ªán lo·∫°i ngu·ªìn (video, image, webcam, ho·∫∑c th∆∞ m·ª•c)
    
    Args:
        source: ƒê∆∞·ªùng d·∫´n file/th∆∞ m·ª•c ho·∫∑c webcam ID
    
    Returns:
        str: 'video', 'image', 'webcam', 'directory', ho·∫∑c None
    """
    # Ki·ªÉm tra webcam
    if isinstance(source, str) and source.isdigit():
        return 'webcam'
    if isinstance(source, int):
        return 'webcam'
    
    # Ki·ªÉm tra file t·ªìn t·∫°i
    if not os.path.exists(source):
        return None
    
    # Ki·ªÉm tra th∆∞ m·ª•c
    if os.path.isdir(source):
        # Ki·ªÉm tra xem th∆∞ m·ª•c c√≥ ch·ª©a ·∫£nh hay video
        extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.webm']
        
        files = os.listdir(source)
        has_images = any(f.lower().endswith(tuple(extensions)) for f in files)
        has_videos = any(f.lower().endswith(tuple(video_extensions)) for f in files)
        
        if has_videos:
            return 'directory_video'
        elif has_images:
            return 'directory_image'
        else:
            return 'directory'
    
    # Ki·ªÉm tra extension
    source_lower = source.lower()
    
    # Video extensions
    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.webm', '.m4v']
    if any(source_lower.endswith(ext) for ext in video_extensions):
        return 'video'
    
    # Image extensions
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp', '.gif']
    if any(source_lower.endswith(ext) for ext in image_extensions):
        return 'image'
    
    return None


def load_args_config(args_path=None):
    """
    Load c·∫•u h√¨nh t·ª´ args.yaml n·∫øu c√≥
    
    Args:
        args_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn args.yaml (None ƒë·ªÉ t·ª± ƒë·ªông t√¨m)
    
    Returns:
        dict: Dictionary ch·ª©a c√°c tham s·ªë t·ª´ args.yaml ho·∫∑c None
    """
    if args_path is None:
        args_path = DEFAULT_ARGS_PATH
    
    if not os.path.exists(args_path):
        return None
    
    try:
        with open(args_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print(f"‚úÖ ƒê√£ load c·∫•u h√¨nh t·ª´: {args_path}")
        return config
    except Exception as e:
        print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ load args.yaml: {e}")
        return None


def track_video_with_pause(model, video_path, output_dir, conf, tracker, imgsz, iou, device, is_webcam):
    """
    Track video v·ªõi kh·∫£ nƒÉng pause/resume khi hi·ªÉn th·ªã
    
    Controls:
    - Space ho·∫∑c 'p': Pause/Resume
    - 'q' ho·∫∑c ESC: Tho√°t
    - 's': Step (ch·ªâ khi ƒëang pause, chuy·ªÉn sang frame ti·∫øp theo)
    """
    
    print("\n‚å®Ô∏è  ƒêi·ªÅu khi·ªÉn:")
    print("   - Ph√≠m SPACE ho·∫∑c 'p': T·∫°m d·ª´ng/Ti·∫øp t·ª•c")
    print("   - Ph√≠m 's': B∆∞·ªõc ti·∫øp (ch·ªâ khi ƒëang pause)")
    print("   - Ph√≠m 'q' ho·∫∑c ESC: Tho√°t")
    
    # M·ªü video
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        print(f"‚ùå Kh√¥ng th·ªÉ m·ªü video: {video_path}")
        return None
    
    # L·∫•y th√¥ng tin video
    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if not is_webcam else 0
    
    # T·∫°o VideoWriter ƒë·ªÉ l∆∞u video
    output_path = os.path.join(output_dir, 'helmet-tracking')
    os.makedirs(output_path, exist_ok=True)
    
    if not is_webcam:
        # L·∫•y t√™n file t·ª´ video_path (c√≥ th·ªÉ l√† string ho·∫∑c Path)
        video_name = os.path.basename(str(video_path))
        output_video_path = os.path.join(output_path, video_name)
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
    else:
        out = None
        output_video_path = None
    
    # Bi·∫øn tr·∫°ng th√°i
    paused = False
    step_mode = False
    frame_count = 0
    total_helmet = 0
    total_no_helmet = 0
    unique_tracks = set()
    
    print(f"\n‚ñ∂Ô∏è  ƒêang ph√°t video... (Nh·∫•n SPACE ƒë·ªÉ pause/resume)")
    
    try:
        while True:
            if not paused or step_mode:
                ret, frame = cap.read()
                if not ret:
                    if is_webcam:
                        continue  # Webcam c√≥ th·ªÉ kh√¥ng c√≥ frame ngay
                    break
                
                frame_count += 1
                step_mode = False
                
                # Track frame
                results = model.track(
                    source=frame,
                    conf=conf,
                    tracker=tracker,
                    save=False,
                    verbose=False,
                    imgsz=imgsz,
                    iou=iou,
                    device=device
                )
                
                # V·∫Ω k·∫øt qu·∫£ l√™n frame
                annotated_frame = results[0].plot()
                
                # Th·ªëng k√™
                if results[0].boxes is not None and len(results[0].boxes) > 0:
                    for box in results[0].boxes:
                        cls = int(box.cls[0])
                        class_name = model.names[cls]
                        
                        # L·∫•y tracking ID n·∫øu c√≥
                        if hasattr(box, 'id') and box.id is not None:
                            track_id = int(box.id[0])
                            unique_tracks.add(track_id)
                        
                        if 'with_helmet' in class_name:
                            total_helmet += 1
                        elif 'without_helmet' in class_name:
                            total_no_helmet += 1
                
                # Th√™m th√¥ng tin l√™n frame
                info_text = f"Frame: {frame_count}"
                if not is_webcam:
                    info_text += f" / {total_frames}"
                if paused:
                    info_text += " [PAUSED]"
                
                cv2.putText(annotated_frame, info_text, (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                # L∆∞u frame
                if out:
                    out.write(annotated_frame)
                
                # Hi·ªÉn th·ªã
                cv2.imshow('Helmet Tracking - Press SPACE to pause, Q to quit', annotated_frame)
            
            # X·ª≠ l√Ω ph√≠m
            key = cv2.waitKey(1 if not paused else 0) & 0xFF
            
            if key == ord('q') or key == 27:  # 'q' ho·∫∑c ESC
                print("\n‚èπÔ∏è  ƒê√£ d·ª´ng video")
                break
            elif key == ord(' ') or key == ord('p'):  # Space ho·∫∑c 'p'
                paused = not paused
                if paused:
                    print("‚è∏Ô∏è  ƒê√£ t·∫°m d·ª´ng (Nh·∫•n SPACE ƒë·ªÉ ti·∫øp t·ª•c, 's' ƒë·ªÉ b∆∞·ªõc ti·∫øp, 'q' ƒë·ªÉ tho√°t)")
                else:
                    print("‚ñ∂Ô∏è  ƒê√£ ti·∫øp t·ª•c")
            elif key == ord('s') and paused:  # Step (ch·ªâ khi pause)
                step_mode = True
                print("‚è≠Ô∏è  B∆∞·ªõc ti·∫øp...")
    
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  ƒê√£ d·ª´ng video (Ctrl+C)")
    finally:
        cap.release()
        if out:
            out.release()
        cv2.destroyAllWindows()
        
        # Th·ªëng k√™
        print(f"\n{'='*60}")
        print("TH·ªêNG K√ä K·∫æT QU·∫¢")
        print(f"{'='*60}")
        print(f"üìä T·ªïng s·ªë frame ƒë√£ x·ª≠ l√Ω: {frame_count}")
        print(f"üë§ T·ªïng s·ªë object ƒë∆∞·ª£c ph√°t hi·ªán:")
        print(f"   - C√≥ m≈© b·∫£o hi·ªÉm: {total_helmet}")
        print(f"   - Kh√¥ng c√≥ m≈© b·∫£o hi·ªÉm: {total_no_helmet}")
        print(f"   - T·ªïng c·ªông: {total_helmet + total_no_helmet}")
        if unique_tracks:
            print(f"üÜî S·ªë l∆∞·ª£ng object unique ƒë∆∞·ª£c track: {len(unique_tracks)}")
        
        print(f"\n‚úÖ Ho√†n th√†nh! K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_path}")
        if not is_webcam and output_video_path and os.path.exists(output_video_path):
            print(f"üìπ Video ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_video_path}")
    
    return None


def track_video(model_path, video_path, output_dir='runs/track', conf=0.25, tracker='bytetrack.yaml', show=False, args_config=None):
    """
    Track objects trong video
    
    Args:
        model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn model ƒë√£ train (.pt)
        video_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn video file ho·∫∑c webcam (0, 1, 2...)
        output_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
        conf: Confidence threshold
        tracker: Lo·∫°i tracker (bytetrack.yaml, botsort.yaml)
        show: Hi·ªÉn th·ªã video real-time
    """
    print(f"\n{'='*60}")
    print("TRACKING VIDEO")
    print(f"{'='*60}")
    
    # Load model
    print(f"ƒêang load model t·ª´: {model_path}")
    try:
        model = YOLO(model_path)
        print("‚úÖ Model ƒë√£ ƒë∆∞·ª£c load th√†nh c√¥ng!")
    except Exception as e:
        print(f"‚ùå L·ªói khi load model: {e}")
        return None
    
    # Ki·ªÉm tra video path
    is_webcam = False
    if isinstance(video_path, str) and video_path.isdigit():
        video_path = int(video_path)
        is_webcam = True
        print(f"üìπ ƒêang s·ª≠ d·ª•ng webcam: {video_path}")
    else:
        if not os.path.exists(video_path):
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y video: {video_path}")
            return None
        print(f"üìπ ƒêang x·ª≠ l√Ω video: {video_path}")
    
    # √Åp d·ª•ng c·∫•u h√¨nh t·ª´ args.yaml n·∫øu c√≥
    imgsz = 640
    iou = 0.7
    device = 0 if torch.cuda.is_available() else 'cpu'
    
    if args_config:
        # L·∫•y c√°c tham s·ªë t·ª´ args.yaml
        if args_config.get('imgsz'):
            imgsz = args_config['imgsz']
        if args_config.get('iou'):
            iou = args_config['iou']
        if args_config.get('device'):
            device = args_config['device']
        if args_config.get('conf') is not None and conf == 0.25:  # Ch·ªâ d√πng n·∫øu ch∆∞a ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
            conf = args_config['conf'] if args_config['conf'] else 0.25
        # L·∫•y tracker t·ª´ args.yaml n·∫øu c√≥ (nh∆∞ng v·∫´n ∆∞u ti√™n tham s·ªë truy·ªÅn v√†o)
        if args_config.get('tracker') and tracker == 'bytetrack.yaml':
            tracker_from_args = args_config['tracker']
            if tracker_from_args in ['bytetrack.yaml', 'botsort.yaml']:
                tracker = tracker_from_args
    
    # Th√¥ng tin x·ª≠ l√Ω
    print(f"\n‚öôÔ∏è  C·∫•u h√¨nh:")
    print(f"   - Confidence threshold: {conf}")
    print(f"   - Tracker: {tracker}")
    print(f"   - Image size: {imgsz}")
    print(f"   - IOU threshold: {iou}")
    print(f"   - Device: {device}")
    print(f"   - Hi·ªÉn th·ªã real-time: {'C√≥' if show else 'Kh√¥ng'}")
    if args_config:
        print(f"   - üìã ƒê√£ √°p d·ª•ng c·∫•u h√¨nh t·ª´ args.yaml")
    print(f"\nüîÑ ƒêang x·ª≠ l√Ω video...")
    
    # Track video
    try:
        # N·∫øu show=True, s·ª≠ d·ª•ng x·ª≠ l√Ω th·ªß c√¥ng ƒë·ªÉ c√≥ th·ªÉ pause
        if show:
            return track_video_with_pause(
                model=model,
                video_path=video_path,
                output_dir=output_dir,
                conf=conf,
                tracker=tracker,
                imgsz=imgsz,
                iou=iou,
                device=device,
                is_webcam=is_webcam
            )
        
        # N·∫øu kh√¥ng show, s·ª≠ d·ª•ng c√°ch c≈© (nhanh h∆°n)
        results = model.track(
            source=video_path,
            conf=conf,
            tracker=tracker,
            save=True,
            project=output_dir,
            name='helmet-tracking',
            exist_ok=True,
            show=False,
            save_txt=True,  # L∆∞u tracking results d·∫°ng text
            save_conf=True,
            line_width=2,
            verbose=True,
            imgsz=imgsz,  # K√≠ch th∆∞·ªõc ·∫£nh x·ª≠ l√Ω t·ª´ args.yaml
            iou=iou,  # IOU threshold t·ª´ args.yaml
            device=device  # Device t·ª´ args.yaml
        )
        
        # Th·ªëng k√™ k·∫øt qu·∫£
        print(f"\n{'='*60}")
        print("TH·ªêNG K√ä K·∫æT QU·∫¢")
        print(f"{'='*60}")
        
        total_frames = 0
        total_helmet = 0
        total_no_helmet = 0
        unique_tracks = set()
        
        for result in results:
            total_frames += 1
            if result.boxes is not None and len(result.boxes) > 0:
                for box in result.boxes:
                    cls = int(box.cls[0])
                    class_name = model.names[cls]
                    
                    # L·∫•y tracking ID n·∫øu c√≥
                    if hasattr(box, 'id') and box.id is not None:
                        track_id = int(box.id[0])
                        unique_tracks.add(track_id)
                    
                    if 'with_helmet' in class_name:
                        total_helmet += 1
                    elif 'without_helmet' in class_name:
                        total_no_helmet += 1
        
        print(f"üìä T·ªïng s·ªë frame ƒë√£ x·ª≠ l√Ω: {total_frames}")
        print(f"üë§ T·ªïng s·ªë object ƒë∆∞·ª£c ph√°t hi·ªán:")
        print(f"   - C√≥ m≈© b·∫£o hi·ªÉm: {total_helmet}")
        print(f"   - Kh√¥ng c√≥ m≈© b·∫£o hi·ªÉm: {total_no_helmet}")
        print(f"   - T·ªïng c·ªông: {total_helmet + total_no_helmet}")
        if unique_tracks:
            print(f"üÜî S·ªë l∆∞·ª£ng object unique ƒë∆∞·ª£c track: {len(unique_tracks)}")
        
        print(f"\n‚úÖ Ho√†n th√†nh! K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_dir}/helmet-tracking")
        if not is_webcam:
            output_video = os.path.join(output_dir, 'helmet-tracking', os.path.basename(video_path))
            if os.path.exists(output_video):
                print(f"üìπ Video ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_video}")
        
        return results
        
    except Exception as e:
        print(f"‚ùå L·ªói khi x·ª≠ l√Ω video: {e}")
        import traceback
        traceback.print_exc()
        return None


def detect_image(model_path, image_path, output_dir='runs/detect', conf=0.25, show=False):
    """
    Detect objects trong ·∫£nh (kh√¥ng c√≥ tracking v√¨ ch·ªâ l√† ·∫£nh ƒë∆°n)
    
    Args:
        model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn model ƒë√£ train (.pt)
        image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh ho·∫∑c th∆∞ m·ª•c ·∫£nh
        output_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
        conf: Confidence threshold
        show: Hi·ªÉn th·ªã ·∫£nh
    """
    print(f"\n{'='*60}")
    print("DETECT ·∫¢NH")
    print(f"{'='*60}")
    
    # Load model
    print(f"ƒêang load model t·ª´: {model_path}")
    model = YOLO(model_path)
    
    # Ki·ªÉm tra image path
    if not os.path.exists(image_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh/th∆∞ m·ª•c: {image_path}")
        return
    
    # Detect ·∫£nh
    results = model.predict(
        source=image_path,
        conf=conf,
        save=True,
        project=output_dir,
        name='helmet-detect',
        exist_ok=True,
        show=show,
        save_txt=True,
        save_conf=True,
        line_width=2,
        verbose=True
    )
    
    # Hi·ªÉn th·ªã th·ªëng k√™
    print(f"\n{'='*60}")
    print("TH·ªêNG K√ä K·∫æT QU·∫¢")
    print(f"{'='*60}")
    
    total_helmet = 0
    total_no_helmet = 0
    
    for result in results:
        for box in result.boxes:
            cls = int(box.cls[0])
            class_name = model.names[cls]
            if 'with_helmet' in class_name:
                total_helmet += 1
            elif 'without_helmet' in class_name:
                total_no_helmet += 1
    
    print(f"T·ªïng s·ªë ng∆∞·ªùi c√≥ m≈© b·∫£o hi·ªÉm: {total_helmet}")
    print(f"T·ªïng s·ªë ng∆∞·ªùi kh√¥ng c√≥ m≈© b·∫£o hi·ªÉm: {total_no_helmet}")
    print(f"T·ªïng s·ªë ng∆∞·ªùi: {total_helmet + total_no_helmet}")
    
    print(f"\n‚úÖ Ho√†n th√†nh! K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_dir}/helmet-detect")
    return results


def main():
    parser = argparse.ArgumentParser(
        description='Tracking v√† Detection m≈© b·∫£o hi·ªÉm v·ªõi YOLO11 - T·ª± ƒë·ªông ph√°t hi·ªán video/·∫£nh',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
V√≠ d·ª• s·ª≠ d·ª•ng:
  # T·ª± ƒë·ªông ph√°t hi·ªán v√† x·ª≠ l√Ω (khuy·∫øn ngh·ªã)
  python track.py --source video.mp4
  python track.py --source image.jpg
  python track.py --source 0  # webcam
  python track.py --source folder/  # th∆∞ m·ª•c ·∫£nh/video
  
  # Ch·ªâ ƒë·ªãnh mode c·ª• th·ªÉ (n·∫øu c·∫ßn)
  python track.py --mode video --source video.mp4
  python track.py --mode image --source image.jpg
  
  # V·ªõi c√°c t√πy ch·ªçn kh√°c
  python track.py --source video.mp4 --conf 0.5 --show
  python track.py --source image.jpg --conf 0.3
        """
    )
    
    parser.add_argument('--mode', type=str, choices=['video', 'image'], default=None,
                       help='Ch·∫ø ƒë·ªô: video (tracking) ho·∫∑c image (detection). N·∫øu kh√¥ng ch·ªâ ƒë·ªãnh, s·∫Ω t·ª± ƒë·ªông ph√°t hi·ªán t·ª´ --source')
    parser.add_argument('--source', type=str, required=True,
                       help='ƒê∆∞·ªùng d·∫´n video/·∫£nh, th∆∞ m·ª•c, ho·∫∑c webcam (0, 1, 2...)')
    parser.add_argument('--model', type=str, default=DEFAULT_MODEL_PATH,
                       help=f'ƒê∆∞·ªùng d·∫´n ƒë·∫øn model ƒë√£ train (m·∫∑c ƒë·ªãnh: {DEFAULT_MODEL_PATH})')
    parser.add_argument('--conf', type=float, default=0.25,
                       help='Confidence threshold (m·∫∑c ƒë·ªãnh: 0.25)')
    parser.add_argument('--tracker', type=str, default='bytetrack.yaml',
                       choices=['bytetrack.yaml', 'botsort.yaml'],
                       help='Lo·∫°i tracker (m·∫∑c ƒë·ªãnh: bytetrack.yaml) - ch·ªâ d√πng cho video')
    parser.add_argument('--show', action='store_true',
                       help='Hi·ªÉn th·ªã k·∫øt qu·∫£ real-time')
    parser.add_argument('--output', type=str, default=None,
                       help='Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£ (m·∫∑c ƒë·ªãnh: runs/track cho video, runs/detect cho ·∫£nh)')
    parser.add_argument('--args', type=str, default=None,
                       help='ƒê∆∞·ªùng d·∫´n ƒë·∫øn args.yaml ƒë·ªÉ load c·∫•u h√¨nh (m·∫∑c ƒë·ªãnh: t·ª± ƒë·ªông t√¨m)')
    parser.add_argument('--no-args', action='store_true',
                       help='Kh√¥ng s·ª≠ d·ª•ng c·∫•u h√¨nh t·ª´ args.yaml')
    
    args = parser.parse_args()
    
    # Load args.yaml n·∫øu c√≥
    args_config = None
    if not args.no_args:
        args_config = load_args_config(args.args)
    
    # Ki·ªÉm tra model
    if not os.path.exists(args.model):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y model t·∫°i: {args.model}")
        print(f"Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n ho·∫∑c train model tr∆∞·ªõc!")
        sys.exit(1)
    
    # Ki·ªÉm tra CUDA
    print(f"PyTorch version: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA device: {torch.cuda.get_device_name(0)}")
    
    # T·ª± ƒë·ªông ph√°t hi·ªán mode n·∫øu kh√¥ng ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
    if args.mode is None:
        source_type = detect_source_type(args.source)
        
        if source_type is None:
            print(f"‚ùå Kh√¥ng th·ªÉ ph√°t hi·ªán lo·∫°i file t·ª´: {args.source}")
            print(f"Vui l√≤ng ch·ªâ ƒë·ªãnh --mode video ho·∫∑c --mode image")
            sys.exit(1)
        
        if source_type in ['video', 'webcam', 'directory_video']:
            args.mode = 'video'
            print(f"‚úÖ T·ª± ƒë·ªông ph√°t hi·ªán: VIDEO")
        elif source_type in ['image', 'directory_image']:
            args.mode = 'image'
            print(f"‚úÖ T·ª± ƒë·ªông ph√°t hi·ªán: ·∫¢NH")
        else:
            print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ x√°c ƒë·ªãnh lo·∫°i file, m·∫∑c ƒë·ªãnh s·ª≠ d·ª•ng mode: image")
            args.mode = 'image'
    else:
        print(f"üìã S·ª≠ d·ª•ng mode ƒë√£ ch·ªâ ƒë·ªãnh: {args.mode.upper()}")
    
    # X·ª≠ l√Ω theo mode
    if args.mode == 'video':
        output_dir = args.output if args.output else 'runs/track'
        track_video(
            model_path=args.model,
            video_path=args.source,
            output_dir=output_dir,
            conf=args.conf,
            tracker=args.tracker,
            show=args.show,
            args_config=args_config
        )
    elif args.mode == 'image':
        output_dir = args.output if args.output else 'runs/detect'
        detect_image(
            model_path=args.model,
            image_path=args.source,
            output_dir=output_dir,
            conf=args.conf,
            show=args.show
        )


def interactive_mode():
    """Ch·∫ø ƒë·ªô t∆∞∆°ng t√°c v·ªõi menu - T·ª± ƒë·ªông ph√°t hi·ªán video/·∫£nh"""
    print(f"\n{'='*60}")
    print("CH∆Ø∆†NG TR√åNH TRACKING M≈® B·∫¢O HI·ªÇM")
    print("T·ª± ƒë·ªông ph√°t hi·ªán video/·∫£nh v√† tracking")
    print(f"{'='*60}\n")
    
    # S·ª≠ d·ª•ng model m·∫∑c ƒë·ªãnh
    model_path = DEFAULT_MODEL_PATH
    print(f"üì¶ S·ª≠ d·ª•ng model: {model_path}")
    
    if not os.path.exists(model_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y model t·∫°i: {model_path}")
        print(f"Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n ho·∫∑c train model tr∆∞·ªõc!")
        return
    
    # T·ª± ƒë·ªông load args.yaml n·∫øu c√≥
    args_config = load_args_config()
    if args_config:
        print(f"üìã ƒê√£ t√¨m th·∫•y args.yaml, s·∫Ω s·ª≠ d·ª•ng c·∫•u h√¨nh t·ª´ file n√†y")
        use_args = input("   S·ª≠ d·ª•ng c·∫•u h√¨nh t·ª´ args.yaml? (y/n) [y]: ").strip().lower()
        if use_args and use_args != 'y':
            args_config = None
    else:
        args_config = None
    
    # Nh·∫≠p source
    print("\nüìÅ Nh·∫≠p ƒë∆∞·ªùng d·∫´n file ho·∫∑c ch·ªçn ngu·ªìn:")
    print("   - Video file: video.mp4, video.avi, ...")
    print("   - ·∫¢nh file: image.jpg, image.png, ...")
    print("   - Th∆∞ m·ª•c: folder/ (t·ª± ƒë·ªông ph√°t hi·ªán ·∫£nh/video)")
    print("   - Webcam: 0, 1, 2, ...")
    source = input("\nƒê∆∞·ªùng d·∫´n ho·∫∑c webcam ID: ").strip()
    
    if not source:
        print("‚ùå Vui l√≤ng nh·∫≠p ƒë∆∞·ªùng d·∫´n ho·∫∑c webcam ID!")
        return
    
    # Lo·∫°i b·ªè d·∫•u ngo·∫∑c k√©p n·∫øu c√≥
    source = source.strip('"').strip("'")
    
    # T·ª± ƒë·ªông ph√°t hi·ªán lo·∫°i source
    source_type = detect_source_type(source)
    
    if source_type is None:
        print(f"‚ùå Kh√¥ng th·ªÉ ph√°t hi·ªán lo·∫°i file t·ª´: {source}")
        print("Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n!")
        return
    
    # Hi·ªÉn th·ªã lo·∫°i ƒë√£ ph√°t hi·ªán
    type_names = {
        'video': 'üìπ Video file',
        'image': 'üñºÔ∏è ·∫¢nh file',
        'webcam': 'üìπ Webcam',
        'directory_video': 'üìÅ Th∆∞ m·ª•c ch·ª©a video',
        'directory_image': 'üìÅ Th∆∞ m·ª•c ch·ª©a ·∫£nh',
        'directory': 'üìÅ Th∆∞ m·ª•c'
    }
    print(f"\n‚úÖ ƒê√£ ph√°t hi·ªán: {type_names.get(source_type, source_type)}")
    
    # Confidence threshold
    print("\n‚öôÔ∏è  Confidence threshold (0.0 - 1.0):")
    print("   - Gi√° tr·ªã th·∫•p (0.1-0.3): Ph√°t hi·ªán nhi·ªÅu h∆°n, c√≥ th·ªÉ c√≥ l·ªói")
    print("   - Gi√° tr·ªã cao (0.5-0.9): Ch√≠nh x√°c h∆°n, c√≥ th·ªÉ b·ªè s√≥t")
    conf_input = input("   Nh·∫≠p gi√° tr·ªã [0.25]: ").strip()
    try:
        conf = float(conf_input) if conf_input else 0.25
        if conf < 0 or conf > 1:
            print("‚ö†Ô∏è  Gi√° tr·ªã kh√¥ng h·ª£p l·ªá, s·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh 0.25")
            conf = 0.25
    except ValueError:
        print("‚ö†Ô∏è  Gi√° tr·ªã kh√¥ng h·ª£p l·ªá, s·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh 0.25")
        conf = 0.25
    
    # X·ª≠ l√Ω theo lo·∫°i source
    if source_type in ['video', 'webcam', 'directory_video']:
        # Tracker - ch·ªâ cho video
        print("\n‚öôÔ∏è  Tracker (thu·∫≠t to√°n theo d√µi object):")
        print("   1. bytetrack.yaml - Nhanh, hi·ªáu qu·∫£ (khuy·∫øn ngh·ªã)")
        print("   2. botsort.yaml - Ch√≠nh x√°c h∆°n, t·ªët cho object di chuy·ªÉn nhanh")
        tracker_choice = input("   L·ª±a ch·ªçn (1/2) [1]: ").strip()
        if tracker_choice == '2':
            tracker = 'botsort.yaml'
        else:
            tracker = 'bytetrack.yaml'
        
        show_input = input("Hi·ªÉn th·ªã video real-time? (y/n) [y]: ").strip().lower()
        show = show_input == 'y' if show_input else True
        
        track_video(model_path, source, conf=conf, tracker=tracker, show=show, args_config=args_config)
    
    elif source_type in ['image', 'directory_image']:
        show = input("Hi·ªÉn th·ªã ·∫£nh? (y/n) [n]: ").strip().lower() == 'y'
        detect_image(model_path, source, conf=conf, show=show)
    
    else:
        # Th∆∞ m·ª•c kh√¥ng x√°c ƒë·ªãnh, h·ªèi ng∆∞·ªùi d√πng
        print("\n‚ö†Ô∏è  Kh√¥ng th·ªÉ x√°c ƒë·ªãnh lo·∫°i file trong th∆∞ m·ª•c")
        print("Ch·ªçn ch·∫ø ƒë·ªô x·ª≠ l√Ω:")
        print("1. X·ª≠ l√Ω nh∆∞ ·∫£nh (detection)")
        print("2. X·ª≠ l√Ω nh∆∞ video (tracking)")
        choice = input("L·ª±a ch·ªçn (1/2) [1]: ").strip()
        
        if choice == '2':
            print("\n‚öôÔ∏è  Tracker:")
            print("   1. bytetrack.yaml - Nhanh, hi·ªáu qu·∫£ (khuy·∫øn ngh·ªã)")
            print("   2. botsort.yaml - Ch√≠nh x√°c h∆°n")
            tracker_choice = input("   L·ª±a ch·ªçn (1/2) [1]: ").strip()
            tracker = 'botsort.yaml' if tracker_choice == '2' else 'bytetrack.yaml'
            show = input("Hi·ªÉn th·ªã real-time? (y/n) [y]: ").strip().lower() == 'y'
            track_video(model_path, source, conf=conf, tracker=tracker, show=show, args_config=args_config)
        else:
            show = input("Hi·ªÉn th·ªã ·∫£nh? (y/n) [n]: ").strip().lower() == 'y'
            detect_image(model_path, source, conf=conf, show=show)


if __name__ == '__main__':
    # N·∫øu kh√¥ng c√≥ tham s·ªë d√≤ng l·ªánh, ch·∫°y ch·∫ø ƒë·ªô t∆∞∆°ng t√°c
    if len(sys.argv) == 1:
        interactive_mode()
    else:
        main()

